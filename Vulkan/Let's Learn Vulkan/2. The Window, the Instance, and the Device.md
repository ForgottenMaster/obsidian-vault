The first things we'll need to do to start using Vulkan will be to open a window to render into, create a Vulkan instance, and create a logical Vulkan device from that instance.

The end result will just show a blank white window as shown below.

![Blank Window](Blank%20White%20Vulkan%20Window.png)

---
# Event loop and window #

The first step which we can get out of the way before even touching Vulkan will be to create a window for us to eventually render into, and an event loop that winit uses to allow us to handle the events from the user such as resizing etc.

The function to create the EventLoop, and the window is fairly straightforward here:

```rust
fn create_event_loop_and_window() -> Result<(EventLoop<()>, Window)> {
    let event_loop = EventLoop::new();
    let window = create_window(&event_loop).context("Error in create_event_loop_and_window")?;
    Ok((event_loop, window))
}
```

As with most of our functions, this returns an **anyhow::Result**. We use anyhow in order to get a common Result/error type to be used and can be propagated up the callstack, additionally allowing us to add context.

In the case of success, we return the event loop, and the window as tuple. If a failure were to occur, we make sure to add appropriate context to the Result we're propagating so that when it's printed out we can see the trace that caused the error.

In order to add context to an anyhow::Result, we use the **context** method as shown in the above snippet.

The event loop is a simple infallible constructor, but the window can fail. We wrap up window construction into the **create_window** method which looks as follows:

```rust
fn create_window(event_loop: &EventLoop<()>) -> Result<Window> {
    WindowBuilder::new()
        .with_resizable(false)
        .with_title("Let's Learn Vulkan")
        .with_inner_size(Size::Physical(PhysicalSize {
            width: 800,
            height: 600,
        }))
        .build(event_loop)
        .context("Error in create_window.")
}
```

In this case, the WindowBuilder requires the EventLoop so we pass that in by reference. On success will return the created window, but it's fallible so we use anyhow::Result again.

We set the window to not be resizable (so that we don't have to deal with swapchain recreation just yet), and fix it to a size of 800x600 for now.

---
# Ash entry point #

The first thing we need to do is to get the entry point object from which we create Vulkan instances. In Ash, which is the Vulkan library we're using, there are two methods of getting the Vulkan entry point:

1. **Entry::linked** - Statically links Vulkan into the program. This requires the Vulkan SDK to be installed on development machine, but executables don't need to dynamically find the Vulkan loader on the target machine.
2. **Entry::load** - Dynamically loads Vulkan on the target machine. This is fallible because Vulkan may fail to be located on the target machine.

We'll use Entry::linked because we have installed the Vulkan SDK on our development machine.

---
# Creating an instance #

Now that we have the window and an entry point, we can create the first kind of object that Vulkan needs to be set up. The first object type is an **instance** and it contains metadata relating to the application name, engine name & version, etc.

It also defines which version of the Vulkan API we're using, and which extensions and layers we want to enable too.

The first thing we'll want is to prepare our application name to pass to the instance creation. Now, this isn't actually necessary...in fact the only thing that's *required* for the app info is the Vulkan API version that we want to use.

#### Preparing our application name ####

The Ash API takes our application name as a CStr object, which is a non-owning value that represents a view into some memory that represents a C-style string.

A C-style string is a byte string which is **null-terminated**.

We can construct a CStr *unsafely* with the from_bytes_with_nul_unchecked associated function. This is marked as unsafe because it expects the bytes that it's given to contain a null-terminator at the end, and doesn't validate that it does.

However, since we're hardcoding the application name byte string in code here, we can guarantee that it's a valid null-terminated string, and can make a CStr with the following code:

```rust
let application_name = unsafe { CStr::from_bytes_with_nul_unchecked(b"Let's Learn Vulkan\0") };
```

#### Application and API versions ####

The application version again is optional, and can be any valid version. The Vulkan API version however is mandatory, and must be only one of a fixed set of version numbers.

In order to construct an arbitrary version from a (variant, major, minor, patch) quartet, we can use the **make_api_version** function from Ash, as **vk::make_api_version(1, 1, 0, 0)**.

For the API version, there are a set of constants that we can use instead. In this case, we'll use API version 1.3 which is the latest as of writing. The constant can be accessed as **vk::API_VERSION_1_3**.

#### ApplicationInfo ####

Ash provides some nice builders for each of the structs Vulkan uses, so we only need to specify those fields we are actually using.

In our case, we will set the application name, version, and API version with the following code:

```rust
let application_info = vk::ApplicationInfo::builder()
    .application_name(application_name)
    .application_version(vk::make_api_version(1, 1, 0, 0))
    .api_version(vk::API_VERSION_1_3);
```

#### Gathering extensions ####

This is where we can specify the extensions we want to enable in the created Vulkan instance, but for now we'll only request the essential extensions that are required to display to the window that we've created.

The ash_window crate we're using can take any **RawDisplayHandle** and give back the list of extensions that we will need to enable to support that display.

Conveniently, winit can return one of these handles for us!. As such, getting the list of required extensions is simply a case of calling the **enumerate_required_extensions** function and passing the display handle from the window.

We can do this with the following code:

```rust
let raw_display_handle = window.raw_display_handle();
let required_extensions = enumerate_required_extensions(raw_display_handle)?;
```

#### Validating extensions ####

Now that we've gathered the extensions we require, we need to validate that those extensions are supported on the target machine. We would get a generic error if we try to create the instance with an extension that's not supported, but checking them ourselves first will let us report a better error message.

We'll go ahead and make a validation function to do this. It will take a slice of ***const i8** which are pointers to C-style strings.

The function will also need access to the ash::Entry instance we made because it uses this to query the available extensions on the machine.

Additionally, the function must be marked as unsafe, because we're accepting a slice of raw pointers and trusting that the caller has ensured they all point to valid null-terminated memory.

The signature of the function then will look as follows:

```rust
unsafe fn validate_required_extensions(
    required_extensions: &[*const i8],
    entry: &Entry,
) -> Result<()> {
    // contents
}
```

We return an anyhow::Result because this is fallible, specifically because we are using it as a way to validate that all the extensions are available. In the case of everything being okay, we don't have any data to return so we make the return type anyhow::Result<()>.

The first step within the function body is to enumerate all available extensions that the system supports. We also want to take these extensions, that are reported as raw pointers, and wrap them into a CStr for comparison. We then collect all the available extensions into a **HashSet** for quick checking:

```rust
let instance_extension_properties = entry.enumerate_instance_extension_properties(None)?;
let available_extensions = instance_extension_properties
    .iter()
    .map(|prop| CStr::from_ptr(prop.extension_name.as_ptr()))
    .collect::<HashSet<_>>();
```

Secondly, we want to give the same treatment to the slice of extension names that was passed in as raw pointers:

```rust
let required_extensions = required_extensions
    .iter()
    .copied() // .iter runs over &*const i8 so copied will let us run over *const i8. This is the same as dereferencing in the map.
    .map(|ptr| CStr::from_ptr(ptr))
    .collect::<Vec<_>>();
```

We then iterate over all the required extensions provided, and check if they are available in the set of available extensions. If one is missing we can return early as an error, with a nicely formatted string telling us the name of the extension that failed:

```rust
for required_extension in required_extensions {
    if !available_extensions.contains(required_extension) {
        return Err(anyhow::anyhow!(format!(
            "Required extension {} is not available",
            required_extension.to_str()?
        )));
    }
}
```

#### Creating the instance creation info ####

Using ash's InstanceCreateInfoBuilder we now have enough information to create an instance. We'll go ahead and make the InstanceCreateInfoBuilder we'll use:

```rust
let instance_create_info = vk::InstanceCreateInfo::builder()
    .application_info(&application_info)
    .enabled_extension_names(required_extensions);
```

#### Creating the instance ####

Finally we can create the Vulkan instance!.

This is done in a single call, but it's unsafe because it's an FFI call. However, we've verified that everything we're providing is configured correctly, so this is a valid call. We just need to wrap in an unsafe block:

```rust
unsafe { entry.create_instance(&instance_create_info, None) }
```

The "None" here is for custom allocation callbacks which can be used to hook in custom behaviour for objects being allocated, deallocated, etc. We won't be using this however so it can stay as None.

---
# Selecting a physical device #

After creating a Vulkan instance which specifies the capabilities of our Vulkan environment as a whole, we next need to select a physical device amongst those on our system that supports the capabilities we'll need for rendering.

Vulkan will give us information on all the Vulkan compatible physical devices (GPUs) on the system, and we can select which one we would like to use based on which is best for our application. Potentially even listing all devices that work for the user to select amongst themselves.

In order to get the available physical devices, we can use a method on the Vulkan instance. It will return an error if it can't retrieve the devices somehow so we'll propagate the error up the chain if we get it. The code looks as follows:

```rust
let physical_devices = unsafe { instance.enumerate_physical_devices() }?;
```

The way we will interact with Vulkan will be by pushing commands onto **queues**, but different physical devices support different numbers and types of queues. These queues are groupes into **queue families** which are grouped by the capabilities of queues within that family.

The capabilities of a queue family are:
- **Graphics**: This is the main queue capability we're interested in. Queues with this capability will be able to take rendering commands that will end up going through the pipeline and can render to a surface or buffer.
- **Compute**: Queue families with this capability will be able to take general computation commands to be processed in a compute shader for example.
- **Transfer**: Transfer queues can be used as dedicated pathways to transfer data quickly to and from the GPU.

We can retrieve the queue family properties for a given PhysicalDevice with the following function call:

```rust
let queue_family_properties = unsafe { instance.get_physical_device_queue_family_properties(device) };
```

The queue family properties contains a bitmask with the capabilities of the family in a field called **queue_flags** that we can check supports the graphics bit with a bitmask. We also need to check that the queue family itself has at least 1 queue in it, which should be the case but we check anyway.

So, we get the list of queue family properties for the physical device, iterate it, find one that supports graphics operations, then....we need to remember the index of that queue family in order to create the actual queues in the Vulkan device.

We actually only need 1 queue family in this case, but we'll still write the function to return a struct containing the indices we care about. It'll make it easy to add more family indices later without changing the function signature.

We'll store these in the following struct:

```rust
struct QueueFamilyIndices {
    graphics_family: u32,
}
```

We'll bundle all of this up into a function to get the required indices from the physical device. It is fallible because the physical device may not have the required queue families, therefore needs to return an Option\<QueueFamilyIndices> to indicate success or failure to find them. Full function looks as follows:

```rust
fn get_queue_family_indices(
    device: vk::PhysicalDevice,
    instance: &Instance,
) -> Option<QueueFamilyIndices> {
    // # Safety
    // This is marked as unsafe because it's an FFI function, but the fact we have an Instance
    // indicates that we're calling it correctly.
    let queue_family_properties =
        unsafe { instance.get_physical_device_queue_family_properties(device) };
    for (idx, props) in queue_family_properties.into_iter().enumerate() {
        if props.queue_count > 0 && props.queue_flags.contains(vk::QueueFlags::GRAPHICS) {
            return Some(QueueFamilyIndices {
                graphics_family: idx as u32,
            });
        }
    }
    None
}
```

In order to select a physical device, then, we simply need to iterate over all the available physical devices and we'll take the first one that has the capabilities we want. It's an error if no physical device on the system supports what we need though, so the function returns a Result. We need to return the PhysicalDevice that was selected, along with the queue family indices for the next step. Full physical device function looks as follows:

```rust
fn get_physical_device(instance: &Instance) -> Result<(vk::PhysicalDevice, QueueFamilyIndices)> {
    {
        // # Safety
        // This is safe because the only way to get an instance is via the Ash API and we would've
        // aborted earlier if one can't be made. The function itself is an FFI function which is why
        // it's marked unsafe but we're confident we're calling it correctly.
        let physical_devices = unsafe { instance.enumerate_physical_devices() }?;
        for physical_device in physical_devices {
            if let Some(queue_family_indices) = get_queue_family_indices(physical_device, instance)
            {
                return Ok((physical_device, queue_family_indices));
            }
        }
        Err(anyhow::anyhow!("Could not find a valid PhysicalDevice."))
    }
    .context("Error in get_physical_device.")
}
```

---
# Creating the Vulkan device #

Now we've selected a physical device to use, we want to actually instruct Vulkan to set up a logical device for us and tell it to allocate us some of the queues for our use.

The function to create a logical device will take as input the physical device, the Vulkan instance, and the queue family indices. Returning as output (if successful) the Device handle, along with handles to the queues that were created for us.

The function signature then looks as follows:

```rust
fn create_logical_device(
    instance: &Instance,
    physical_device: vk::PhysicalDevice,
    queue_family_indices: &QueueFamilyIndices,
) -> Result<(Device, QueueHandles)>
```

The first step will be to create the device itself. For this, we need to specify the queue families we will be using along with how many queues we want to allocate for us. We don't actually specify this count as a number though, but as a slice of **queue priorities**. 

Queue priorities are not guaranteed to be respected by the implementation but *may* be used as a hint to allocate more or less processing time to specific queues. We only have 1 queue so we'll just request a priority of 1.0.

Device creation can fail, so we need to propagate the Result if it does, the device creation code then looks as follows:

```rust
let device = unsafe {
    instance.create_device(
        physical_device,
        &vk::DeviceCreateInfo::builder().queue_create_infos(&[
            *vk::DeviceQueueCreateInfo::builder()
                .queue_family_index(queue_family_indices.graphics_family)
                .queue_priorities(&[1.0]),
        ]),
        None,
    )
}?;
```

After creating the device, Vulkan has allocated us the queues we requested but in order to submit commands to them, we're gonna need to grab their handles. We can do this by calling **get_device_queue** on the created Device, passing the queue family, and index of the queue we want to get the handle for. We'll stash these into a new struct:

```rust
struct QueueHandles {
    graphics_queue: vk::Queue,
}
```

And the code to grab the handle and initialise the struct is as follows:

```rust
let queues = QueueHandles {
    _graphics_queue: unsafe {
        device.get_device_queue(queue_family_indices.graphics_family, 0)
    },
};
```

---
# Running the event loop #

We've not constructed the Vulkan instance and device, we want to now keep the window and application open until quitting the application is requested. This will be dependant on the windowing library in use, but for winit we do this by calling **run_return** on the EventLoop. This will keep the app running in the provided closure until termination is requested. It also returns the error code, so the entire run_event_loop function looks as follows:

```rust
fn run_event_loop(mut event_loop: EventLoop<()>, window: Window) -> i32 {
    event_loop.run_return(move |event, _, control_flow| {
        *control_flow = ControlFlow::Wait;

        match event {
            Event::WindowEvent {
                event: WindowEvent::CloseRequested,
                window_id,
            } if window_id == window.id() => *control_flow = ControlFlow::Exit,
            _ => (),
        }
    })
}
```

This is stating that if we receive a "CloseRequested" windowing event, and the window id we're closing is ours, then set the control flow to ControlFlow::Exit which will cause winit to leave the run_return method and go back to caller

---
# Cleaning up #

In order to "properly" clean up as we're terminating the application, we should tell Vulkan to destroy the device and instance as we're done with it, which will let Vulkan use those queues and such for other applications.

We do that with the following:

```rust
fn cleanup(instance: Instance, device: Device) {
    unsafe {
        device.destroy_device(None);
        instance.destroy_instance(None);
    }
}
```

---
# Putting it all together #

For completion, the main function of our application looks like this:

```rust
fn main() -> Result<()> {
    {
        let (event_loop, window) = create_event_loop_and_window()?;
        let entry = Entry::linked();
        let instance = create_vulkan_instance(&entry, window.raw_display_handle())?;
        let (physical_device, queue_family_indices) = get_physical_device(&instance)?;
        let (logical_device, _queues) =
            create_logical_device(&instance, physical_device, &queue_family_indices)?;
        let error_code = run_event_loop(event_loop, window);
        cleanup(instance, logical_device);
        if error_code == 0 {
            Ok(())
        } else {
            Err(anyhow::anyhow!(format!(
                "Application exited with error code {error_code}"
            )))
        }
    }
    .context("Error in main.")
}
```