We now have a triangle rendering to the screen which proves that our setup is all correct and valid. However currently our vertex positions and colors are baked into our vertex shader.

The next step is to allow our application to define the vertex data to be passed into our graphics pipeline, which we can do with **vertex buffers**.

---
# Vertex Data #

The first thing we want to do is to define how we will store our vertex data. Data for each vertex is stored bundled together and the vertex buffer will be an array of these structures tightly packed.

```rust
#[repr(C)]
struct Vertex {
    position: [f32; 3], // offset 0
    color: [f32; 3],    // offset 12
}
```

We store a position and a colour for each vertex, with each being an array of 3 elements, each of type f32. This matches up with the types we'll define in our vertex shader.

Tagging the struct as repr(C) prevents Rust from re-ordering these fields, which Rust is usually allowed to do for optimisation purposes. We don't want the position and colour fields re-arranged because we rely on a particular layout in memory in order to be compatible with the vertex shader.

---
# Vertex Shader #

Next, we need to update our vertex shader itself.

Previously, we had the arrays of positions and colours baked into the shader, and were using the gl_VertexID to index into those arrays. However we now replace those arrays with two **in parameters** in the Vertex shader

```rust
layout(location = 0) in vec3 position;
layout(location = 1) in vec3 colour;
```

Note that these need different **location** values, which will be indexes into the array of descriptors we will provide to our graphics pipeline shortly.

We can just go ahead and use these values directly in our shader. No gl_VertexID required!

```rust
void main() {
    gl_Position = vec4(position, 1.0);
    fragColour = colour;
}
```

fragColour is our **out parameter** that will be passed along to the fragment shader as before.

---
# Graphics Pipeline #

Now that we've changed the app side to be able to represent this vertex data as an array of structs, and we've changed the vertex shader to define the data from those structs that it needs access to, we now need to tell the graphics pipeline *how* to map individual fields of the Vertex struct to the parameters of the shader.

First of all, it would be helpful to visualise how these vertices are actually laid out in memory

![[Vertex Layout In Memory.png]]

This is how our vertices will be laid out in the buffer sequentially, but we need to tell the pipeline how to chunk this up, and how it knows the data for a single vertex.

#### Bindings ####

Firstly though, there is the possibility to have multiple **bindings** which are completely separate data streams essentially. We defined our position for example in our vertex shader as

```rust
layout(location = 0) in vec3 position;
```

But this is shorthand for using the default binding number of 0, so we could write this as

```rust
layout(binding = 0, location = 0) in vec3 position;
```

We only have one stream of data (our vertex buffer) so we only need one binding. But this could be useful if we store positions and colours in separate buffers for example.

In order to define a binding, Vulkan needs to know the **stride**, and **input rate** of the data coming in.

Input rate is either vertex or instance and defines the way in which the data is consumed from the buffers
- **Vertex** identifies that the stride represents the size of an individual vertex, and each vertex will be pulled one at a time
- **Instance** identifies that the stride represents the total size of all an instances vertices

In our case we just pick Vertex because of the way we define our stride.

Stride in our case, is simply the size of a Vertex struct instance. This is the number of bytes that Vulkan will skip forward by to get to the next vertex. As can be seen in the visual diagram above, the stride of a Vertex is the size of the position array plus the size of the colour array. Both arrays are 12 bytes (3*4 byte floats) so the stride of the Vertex is 24.

Coding this up, we can define an array of bindings, with a single binding (binding index 0)

```rust
let binding_descriptions = [*VertexInputBindingDescription::builder()
    .stride(mem::size_of::<Vertex>().try_into().unwrap())
    .input_rate(VertexInputRate::VERTEX)];
```

#### Attributes ####

Now that we've defined our data streams and the strides within them, we now need to define how individual components within that stream are found, **which** shader locations they are bound to, and **how** they are interpreted.

Once again looking at the diagram above, we have

1. Position
    - Binding: 0
    - Location: 0
    - Offset: 0 bytes
    - Format: R32G32B32_SFLOAT (3-channel, 4-bytes-per-channel, signed float)
2. Color
    - Binding: 0
    - Location: 1
    - Offset: 12 bytes
    - Format: R32G32B32_SFLOAT

0 is the default value for binding, location, and offset so we don't have to mention it for the first attribute.

Coding those attributes up we have

```rust
let attribute_descriptions = [*VertexInputAttributeDescription::builder().format(Format::R32G32B32_SFLOAT),
    *VertexInputAttributeDescription::builder()
        .location(1)
        .format(Format::R32G32B32_SFLOAT)
        .offset(12),
];
```

#### Pipeline ####

Now we can simply add these bindings and attributes to the pipeline by modifying the **PipelineVertexInputStateCreateInfo**

```rust
let vertex_input = PipelineVertexInputStateCreateInfo::builder()
    .vertex_binding_descriptions(&binding_descriptions)
    .vertex_attribute_descriptions(&attribute_descriptions);
```

And the rest of the pipeline can stay the same.

---
# Vertex Buffer #

Vulkan decouples the resources you're using (buffers, images, etc.) from the actual memory allocated for those resources. This is so that the developer could allocate one large "slab" of memory and have it contain many resources using it as the following diagram indicates

![[Memory Allocation.png]]

Alignment requirements as indicated in the image are resource specific so when we create a resource we are able to query from Vulkan what requirements on memory it has. As long as we provide memory that matches, Vulkan doesn't care where it comes from.

Ideally you would allocate a single allocation and use that for storing interleaved data with different offsets/strides as in the diagram below.

![[Buffer Offsets.png]]

For our use-case right now we'll allocate a memory allocation for the vertex buffer only though. We're only learning Vulkan so we can leave these "best practices" until later.

Following are the steps involved in creating a Vulkan buffer, which we'll follow to create a buffer for our vertex data.

#### Creating the Buffer Resource ####

Firstly, we need to tell Vulkan that we will be creating a buffer such that it can assign us an opaque handle to refer to that buffer. As mentioned above, there's no memory connected to the buffer, we're just telling Vulkan how the buffer will be used and what shape it has.

Code is as follows

```rust
let buffer = unsafe {
    device
        .create_buffer(
            &BufferCreateInfo::builder()
                .size((mem::size_of::<Vertex>() * vertices.len()) as u64)
                .usage(BufferUsageFlags::VERTEX_BUFFER)
                .sharing_mode(SharingMode::EXCLUSIVE),
            None,
        )
        .context("Failed to create a buffer.")?
};
```

There are 3 important arguments we're giving to the BufferCreateInfo here
1. The size of the buffer (in bytes). This is the size of a single Vertex multiplied by the number of vertices. There's no additional data to be stored so this is an easy calculation.
2. The buffer usage. Vulkan doesn't know what kind of buffer this is until we tell it, in this case we want a vertex buffer.
3. The sharing mode. A buffer can either be exclusive to a queue family, or shared by multiple queue families much like when we created our image views (another resource). In our case we only use the buffer within the graphics queue family.

#### Allocating Memory ####

Vulkan gives us back an opaque Buffer handle after creation but we now need to allocate some memory for it.

Firstly, Vulkan will only allow memory to be created from some memory types. We can access the memory properties that a Buffer requires by calling a simple function with the buffer handle

```rust
let memory_requirements = unsafe { device.get_buffer_memory_requirements(buffer) };
```

Now that we have the requirements, we need to know what is available on our **physical** device, which again is a simple call

```rust
let memory_properties =
    unsafe { instance.get_physical_device_memory_properties(physical_device) };
```

Now we need to locate a memory type from memory_properties which is supported for the created buffer. We'll wrap this up into a function called find_valid_memory_type_index

```rust
fn find_valid_memory_type_index(
    memory_properties: PhysicalDeviceMemoryProperties,
    memory_requirements: MemoryRequirements,
    flags: MemoryPropertyFlags,
) -> Option<usize>
```

We take in the memory_properties and memory_requirements we look up, but what's this **MemoryPropertyFlags** we're passing?.

Well memory has other properties defining visibility to the CPU/GPU and we can specify what we would like. For our use case we use

1. **Host Visible** - This means that the CPU can see the memory. It might not be located on the CPU, but could have special mapping so it's visible to the CPU
2. **Host Coherent** - This means that the memory doesn't have any special caching so when we write to it, we don't need to flush the cache for example

The memory flags are easy to test - it's a bitmask we can use to check against the memory type's **property_flags**.

The memory requirements is also a bitset, but it's a bitset where a bit set to 1 in the ith position (from the right hand side) means that the memory type at index i is valid.

We can therefore get an iterator over all the memory types, enumerate the iterator to get the index along with the type information, and then find the position of the first memory type that is supported, and matches our bitmask with the following code

```rust
memory_properties
    .memory_types
    .into_iter()
    .enumerate()
    .position(|(index, memory_type)| {
        (memory_requirements.memory_type_bits & (1 << index as u32)) != 0
            && memory_type.property_flags.contains(flags)
    })
```

After we find the index of a valid memory type, we can ask Vulkan to actually allocate the memory for us

```rust
let buffer_memory = unsafe {
    device
        .allocate_memory(
            &MemoryAllocateInfo::builder()
                .allocation_size(memory_requirements.size)
                .memory_type_index(memory_type_index as u32),
            None,
        )
        .context("Failed to allocate vertex buffer memory.")?
};
```

Note that we get the allocation size from memory_requirements.size rather than using the size we originally requested the buffer to have. This is because due to alignment or other requirements, Vulkan may end up requiring more bytes than we need for the buffer itself.

Finally, we can bind the memory to the buffer. Vulkan lets us give an offset into the memory in case we're using memory for multiple resources, but here we just say no offset

```rust
unsafe {
    device
        .bind_buffer_memory(buffer, buffer_memory, 0)
        .context("Failed to bind the buffer memory to the vertex buffer.")?;
}
```

#### Writing Vertex Data ####

Finally we now have to get our Vertex data into the dedicated memory for the buffer to make it available and visible when we come to binding it to our shader.

In order to get a pointer through which we can write, we need to **map** the correct range of memory, Vulkan will then return us a pointer to write with

```rust
let write_ptr = unsafe {
    device
        .map_memory(
            buffer_memory,
            0,
            memory_requirements.size,
            MemoryMapFlags::empty(),
        )
        .context("Failed to map the buffer memory.")? as *mut Vertex
};
```

Again, we pass an offset of 0, and a size of memory_requirements.size because we just want to map the entire range.

We can now go ahead and copy our data into the provided mapped pointer, which in Rust we can do with the std::ptr::copy method which is like a memcpy in C

```rust
unsafe { ptr::copy(vertices.as_ptr(), write_ptr, vertices.len()) };
```

And finally once we're done writing to it, we unmap the memory which allows Vulkan to make use of it knowing we're finished setting the memory

```rust
unsafe { device.unmap_memory(buffer_memory) };
```

And with that, our vertex data is inside the newly allocated memory, and bound to the newly allocated Buffer handle!

#### Clean-up ####

We also need to remember to clean this up on app shutdown. Specifically we need to *free* the memory, and *destroy* the buffer resource.

```rust
device.free_memory(vertex_buffer_memory, None);
device.destroy_buffer(vertex_buffer, None);
```

---
# Command Buffer #

The final thing we need to do is to update our code that is recording into the command buffer to set things up for the draw call.

Specifically we need two things:
1. Bind the vertex buffer(s) to make the data available for the draw call
2. Pass the correct number of vertices into the draw call

Firstly, there's the binding. The command to bind the vertex buffer actually handles multiple so we can bind multiple at the same time. 

We can also specify offsets to use in the buffers we provide, and the number of buffers we provide is going to determine the binding indices.

In our case we only bind one vertex buffer, with an offset of 0. We also tell Vulkan to start binding indices at 0, so the first vertex buffer has binding 0 and that matches up with what our shader expects.

```rust
device.cmd_bind_vertex_buffers(*command_buffer, 0, &[vertex_buffer], &[0]);
```

For the draw call we simply change from drawing 3 vertices to drawing however many we have in the list

```rust
device.cmd_draw(*command_buffer, vertex_count.try_into().unwrap(), 1, 0, 0);
```

---
# Main #

Now we simply need to fill out our vertex buffer in main so it can be passed along as needed. The vertex data will look like this, moved from where we had it baked into the vertex shader.

```rust
let vertex_data = [
    Vertex {
        position: [0.0, -0.4, 0.0],
        color: [1.0, 0.0, 0.0],
    },
    Vertex {
        position: [0.4, 0.4, 0.0],
        color: [0.0, 1.0, 0.0],
    },
    Vertex {
        position: [-0.4, 0.4, 0.0],
        color: [0.0, 0.0, 1.0],
    },
];
```

Running the code to verify we have exactly the same output as before, we see that we do!

![Triangle](Vulkan%20Triangle.png)

Now lets try changing the vertex data to define a square, and check that the same shader can be used to render that too!

![Square](Vulkan%20Square.png)