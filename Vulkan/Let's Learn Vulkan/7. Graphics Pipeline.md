Now that we have somewhere to render to (surface), and something to render with (swapchain), we need to define how to render. This is going to be the responsibility of the graphics pipeline which we must set up manually.

---
# Overview #

An overview of the graphics pipeline is shown below

![[Graphics Pipeline Overview.svg]]

The sections highlighted in yellow indicate those sections which we can program through shader modules. The green stages are fixed functionality, but we can tweak the settings for them.

The stages are described briefly below
1. **Input assembly**: This stage is where the input buffers are taken and assembled/interpreted as some kinds of primitives. This stage assembles the input primitives (such as lines or triangles) from the input data buffers.
2. **Vertex shader**: This stage is where we are able to modify the vertices coming in, such as determining their final position, but also we are able to define per-vertex data here too that is passed along the pipeline.
3. **Tesselation**: This is able to break up primitives such as triangles into smaller triangles before being passed along to the next stage
4. **Geometry shader**: A geometry shader is able to create brand new geometry as part of the pipeline.
5. **Rasterization**: The rasterizer takes the per-vertex data that has been calculated, and determines the attributes at a given pixel/fragment on screen. For example the fragments of a filled triangle, where the data for a fragment is interpolated from the triangle vertices.
6. **Fragment shader**: This stage allows us to determine the final properties and color of a fragment.
7. **Color blending**: This blends the fragment color with the existing contents of the framebuffer to allow for transparency on closer objects to the camera for example.

The first things we'll need to create in Vulkan before we can create the graphics pipeline itself are the **pipeline layout** and the **render pass**.

---
# Pipeline Layout #

The pipeline layout is required to be created first and it tells Vulkan which resources a pipeline has access to and how they are bound. It contains both **descriptor sets** and **push constant ranges** but for now we will just ignore them entirely.

The creation function is actually super small so here it is in its entirety

```rust
fn create_pipeline_layout(device: &Device) -> Result<PipelineLayout> {
    unsafe {
        device.create_pipeline_layout(
            &PipelineLayoutCreateInfo::builder()
                .set_layouts(&[])
                .push_constant_ranges(&[]),
            None,
        )
    }
    .context("Error trying to create a pipeline layout.")
}
```

Note that we're passing empty slices for descriptor set layouts, and push constant ranges.

---
# Render Pass #

In contrast to the pipeline layout, the render pass is a little more involved to set up but it's not too bad conceptually.

A render pass defines three main things:
1. The **attachments** for the render pass. These define the formats for the bound resources/images used in a render pass, including their initial layout (before the render pass starts) and their final layout (after the render pass ends).
2. The **subpasses** of the render pass. When the render pass runs, it will run each of the subpasses. Each subpass specifies which attachments it requires, along with the point in the graphics pipeline that that subpass will run.
3. The **subpass dependencies**. These are required to let Vulkan know which stages need to happen before a subpass, and which can happen only after a subpass.

We'll create a function to make our render pass, it'll take the device, and also the format of our swapchain images so we can set up a colour attachment with the same format.

#### Attachment Descriptions ####

The first thing we'll need to figure out to create a render pass is which attachments we require. Each attachment will have a specific format, along with a sampling mode. Additionally we need to define which layout the attachment starts the render pass with, and which layout it should have after the render pass has finished.

Layout is not the same as format though. Format is the number of bits per pixel, number of channels, etc. such as R8G8B8A8. Layout specifies how these bytes are laid out in memory for a particular purpose.

For this simple renderer, we only need a single attachment that will be set to be ready to be presented after the render pass

```rust
let attachment_descriptions = [*AttachmentDescription::builder()
    .format(format)
    .samples(SampleCountFlags::TYPE_1)
    .load_op(AttachmentLoadOp::CLEAR)
    .store_op(AttachmentStoreOp::STORE)
    .stencil_load_op(AttachmentLoadOp::DONT_CARE)
    .stencil_store_op(AttachmentStoreOp::DONT_CARE)
    .initial_layout(ImageLayout::UNDEFINED)
    .final_layout(ImageLayout::PRESENT_SRC_KHR)];
```

The rationale for the setup here is as follows
1. **format**: Set to the same format as the images in our swapchain (passed into the create_render_pass function). This is because we will be using one of the images from the swapchain as attachment so requires the same format.
2. **samples**: Set to the same number of samples as the images in the swapchain again.
3. **load_op**: This is set to clear. This is the operation we want to perform on the attachment before the render pass is started. In our case we want to clear the attachment to a known good value.
4. **store_op**: This is which operation we want to perform on the attachment after the render pass is finished. In this case we want to store the values for later presentation.
5. **stencil_load_op**/**stencil_store_op**: Set both of these to "Don't care" because we're not using a stencil buffer at the moment.
6. **initial_layout**: This is the initial layout for the image before the render pass starts. In this case we don't really mind what the layout is when we start the pass, it's undefined - it'll be set to a different layout for our subpass soon.
7. **final_layout**: Because we're going to be presenting this attachment to the surface, we want it to be put into a layout optimal for that purpose at the end of the render pass.

#### Subpass Descriptions ####

Next we need to define our subpass(es). In our case we have only a single subpass which will use our attachment as a colour attachment.

The subpasses don't deal with the attachments directly but instead deal with **attachment references** which are able to refer to the specific attachment but define that it should be put into a different format.

The subpass descriptions themselves are easy enough

```rust
let attachment_references = [*AttachmentReference::builder()
    .attachment(0)
    .layout(ImageLayout::COLOR_ATTACHMENT_OPTIMAL)];
let subpass_descriptions = [*SubpassDescription::builder()
    .pipeline_bind_point(PipelineBindPoint::GRAPHICS)
    .color_attachments(&attachment_references)];
```

Here we
1. Define a single attachment reference which refers to the attachment we defined earlier (attachment #0), and with layout optimal for being a colour attachment.
2. Binds to the graphics pipeline.

#### Subpass Dependencies ####

Subpass dependencies are where we need to specify the stages at which the layout transitions for our attachments can happen.

In our case we have only a single subpass, but this subpass will need to perform a transition from "undefined" (at the start of the render pass) to "color attachment optimal" (for the subpass).

However there will be other commands submitted to the GPU before our render pass potentially starts, so we need to let Vulkan know **when** this can happen.

There is a special subpass ID that vulkan uses called VK_SUBPASS_EXTERNAL to identify "everything before" or "everything after" our render passes.

In our case, we are only allowed to perform a transition once we're allowed to write to our color attachments. Therefore our one dependency will be between "external" and our subpass 0

```rust
let subpass_dependencies = [*SubpassDependency::builder()
    .src_subpass(SUBPASS_EXTERNAL)
    .dst_subpass(0)
    .src_stage_mask(PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT)
    .dst_stage_mask(PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT)
    .src_access_mask(AccessFlags::empty())
    .dst_access_mask(AccessFlags::COLOR_ATTACHMENT_WRITE)];
```

A brief summary is as follows
1. **src_subpass**: We are dependant upon the "external" subpass here, which is everything outside our render pass.
2. **dst_subpass**: This is subpass 0 that we're defining our dependency for.
3. **src_stage_mask**/**dst_stage_mask**: The transition can happen at the colour attachment output stage.
4. **src_access_mask**: We don't need any particular memory access to start the transition. Just getting into the COLOR_ATTACHMENT_OUTPUT stage is sufficient.
5. **dst_access_mask**: We need to wait until we're allowed to write to the colour attachment.

#### Creating the Render Pass ####

We can now go ahead and slap all these together to make our render pass

```rust
device.create_render_pass(
    &RenderPassCreateInfo::builder()
        .attachments(&attachment_descriptions)
        .subpasses(&subpass_descriptions)
        .dependencies(&subpass_dependencies),
    None,
)
```

---
# Graphics Pipeline #

With the above prerequisites created, we can go ahead and create a graphics pipeline. For now, we'll bake most of the settings in, though we will need to take the layout and render pass in, along with a few other things. Signature of our create_graphics_pipeline function will look as follows

```rust
fn create_graphics_pipeline(
    vertex_shader: ShaderModule,
    fragment_shader: ShaderModule,
    swapchain_extents: Extent2D,
    pipeline_layout: PipelineLayout,
    render_pass: RenderPass,
    device: &Device,
) -> Result<Pipeline>
```

#### Shader Stages ####

We firstly go ahead and take the two shader modules for vertex and fragment shaders and add the additional information that Vulkan will need to interface with them.

Firstly, we need to define the name of the main function as a CStr. Both of our shaders use the name "main" as the entry point, so we can just create this name and re-use it

```rust
let name = unsafe { CStr::from_bytes_with_nul_unchecked(b"main\0") };
```

We then define our array of shader stages and create a stage each for vertex and fragment shaders

```rust
let shader_stages = [
    *PipelineShaderStageCreateInfo::builder()
        .stage(ShaderStageFlags::VERTEX)
        .module(vertex_shader)
        .name(name),
    *PipelineShaderStageCreateInfo::builder()
        .stage(ShaderStageFlags::FRAGMENT)
        .module(fragment_shader)
        .name(name),
];
```

#### Vertex Input ####

The vertex input stage is where we define sources for our vertex data. However at the moment our vertex data is baked into the vertex shader and as such, we can go ahead and use the default version for now

```rust
let vertex_input = PipelineVertexInputStateCreateInfo::builder();
```

#### Input Assembly ####

This defines how we are interpreting the vertex data coming in, whether it be lines or triangles for example. There are two components to this
1. **Topology**: This is the main component and defines whether we are processing the input data as points, lines, or triangles. Within these primitives we can choose to have them in list form or strip form. We choose triangle list, so every group of 3 vertices will make a triangle and no data is shared.
2. **Primitive Restart**: This allows us to use a special index when rendering using indexed data, to indicate that the primitive should be restarted. For example, if we're rendering a strip of triangles, then every additional vertex from #4 onwards will be linked with the previous 2 to make a triangle. We can use the special restart index to instead forget those two previous triangles and start a new triangle with the next 3 verts. We will disable this

```rust
let input_assembly = PipelineInputAssemblyStateCreateInfo::builder()
    .topology(PrimitiveTopology::TRIANGLE_LIST)
    .primitive_restart_enable(false);
```

#### Viewport State ####

We next need to define our **viewports** and **scissors** which will control which portion of the image will be rendered to, and whether ay of it is clipped off.

As a visual representation of viewports and scissors, take the following image (image from Vulkan Tutorial)

![[Viewport And Scissor Difference.png]]

**Viewport** defines the offset and size of the image that we'll render to as if it's the entire screen. If a viewport is stretched or squished then the rendered image will be too.

**Scissor** defines the area that will be clipped off. This does not stretch or squish the image, but anything outside of the scissor rectangle will instead be cropped out.

For our case we'll have:
- **1 viewport** which starts at offset (0,0) and has the same extents as the swapchain images. Thus, this viewport takes up the entire image. We set the max depth to 1.0 which is the maximum that Vulkan goes to under normalized coordinates.
- **1 scissor** which also covers the entire swapchain image.

```rust
let viewports = [Viewport {
    width: swapchain_extents.width as f32,
    height: swapchain_extents.height as f32,
    max_depth: 1.0,
    ..Viewport::default()
}];
let scissors = [Rect2D {
    extent: swapchain_extents,
    ..Rect2D::default()
}];
let viewport_state = PipelineViewportStateCreateInfo::builder()
    .viewports(&viewports)
    .scissors(&scissors);
```

#### Rasterization ####

The rasterization stage is where the pipeline takes the per-vertex data determined by the vertex, tesselation, and geometry shaders and interpolates that data across the fragments.

It can cull out back facing primitives which it determines by winding order

```rust
let rasterization_state = PipelineRasterizationStateCreateInfo::builder()
    .polygon_mode(PolygonMode::FILL)
    .cull_mode(CullModeFlags::BACK)
    .front_face(FrontFace::CLOCKWISE)
    .line_width(1.0);
```

For our use case
- **polygon_mode**: This is the way that the polygons should be filled in. In this case we just want to completely fill our polygons/triangles.
- **cull_mode**: This determines which side if any of the rendered polygons are culled out when facing the camera. We say that the back faces of polygons are culled out.
- **front_face**: This determines the winding order resulting in the front face of the polygon. We choose clockwise which means that when you're looking at the polygon straight-on, if the vertices are plotted in a clockwise fashion, it has its front face toward you.
- **line_width**: We set the line width to 1.0 here, but it's possible with extensions to have thicker lines.

#### Multisample ####

This one is pretty straightforward - we're not yet using multisampling, so we set it to 1 sample

```rust
let multisample = PipelineMultisampleStateCreateInfo::builder()
    .rasterization_samples(SampleCountFlags::TYPE_1);
```

#### Colour Blending ####

Colour blending determines how a new fragment's colour is blended with an existing fragment in the framebuffer. This is used to have transparency/translucency on objects in the scene.

The basic formula for calculating the final color for a fragment is: **color_op((src_color_blend_factor * src_color),(dst_color_blend_factor * dst_color))**

In our case when blending, we want to multiply the new (src) color by its alpha, and the old (dst) color by 1-src_alpha, then add them together.

For example, if the incoming fragment has an alpha of 1 then the resulting fragment is set to the new color. If it has an alpha of 0, then the resulting fragment ends up being the old color. If 0.5, then the result will be halfway between the two colors.

For alpha value though, we don't want to keep the old alpha, but just keep the new alpha (not that it's used at all when it's in the framebuffer).

The resulting code then looks as follows

```rust
let color_blend_attachments = [*PipelineColorBlendAttachmentState::builder()
    .blend_enable(true)
    .color_write_mask(ColorComponentFlags::RGBA)
    .src_color_blend_factor(BlendFactor::SRC_ALPHA)
    .dst_color_blend_factor(BlendFactor::ONE_MINUS_SRC_ALPHA)
    .color_blend_op(BlendOp::ADD)
    .src_alpha_blend_factor(BlendFactor::ONE)
    .dst_alpha_blend_factor(BlendFactor::ZERO)
    .alpha_blend_op(BlendOp::ADD)];
let color_blend =
    PipelineColorBlendStateCreateInfo::builder().attachments(&color_blend_attachments);
```

As another brief rundown of these settings
1. **blend_enable**: Set to true because we are wanting to blend colors
2. **color_write_mask**: Which components of our fragments we are operating on
3. **src_color_blend_factor**: We use the alpha of the incoming fragment to determine how much of its color is used
4. **dst_color_blend_factor**: We use 1-the alpha of the incoming fragment to determine how much of the fragment already in the framebuffer to use
5. **color_blend_op**: We want to add these together to get the final blended color
6. **src_alpha_blend_factor**: We want to just keep the new alpha
7. **dst_alpha_blend_factor**: We don't care what the old alpha was
8. **alpha_blend_op**: Again we just add them together

#### Pipeline Creation ####

We can now finally just throw everything together to make our pipeline. Note that Vulkan allows us to create multiple pipelines at once so we need to specify a list of creation structs.

```rust
let graphics_pipeline_create_infos = [*GraphicsPipelineCreateInfo::builder()
    .stages(&shader_stages)
    .vertex_input_state(&vertex_input)
    .input_assembly_state(&input_assembly)
    .viewport_state(&viewport_state)
    .rasterization_state(&rasterization_state)
    .multisample_state(&multisample)
    .color_blend_state(&color_blend)
    .layout(pipeline_layout)
    .render_pass(render_pass)
    .subpass(0)];
unsafe {
    let pipelines = device
        .create_graphics_pipelines(PipelineCache::null(), &graphics_pipeline_create_infos, None)
        .map_err(|(_, e)| e)?;
    Ok(pipelines[0])
}
```

We need to call map_err on the return Result because Vulkan actually returns to us the pipelines created before an error occurred, along with the error. We don't care too much about the already-created pipelines....although we could/should destroy them if this were production quality.

We know we're creating only a single pipeline so we then go ahead and return pipelines[0].