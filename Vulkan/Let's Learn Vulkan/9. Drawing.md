We can finally start drawing on the screen now that we've got our framebuffers and recorded our command buffers. In order to render to the screen we will have to acquire an image from the swapchain, submit our command buffer that we recorded to the graphics queue, and then submit the image for presentation on the presentation queue. We will also however need to worry about **synchronization**.

---
# Semaphores & Fences #

There are two kinds of synchronization primitives in Vulkan which are
- **Semaphores**: Synchronize one GPU action with another GPU action. These are reset automatically by the GPU
- **Fences**: Synchronize the CPU with a GPU action by blocking. We can wait for a fence to be signalled, and then have to manually reset it

For our drawing, we will use 2 semaphores and 1 fence with the following semantics
- **Semaphore 1**: Will be used to sequence the playback of the command buffer so it only occurs after the image is ready in the swapchain
- **Semaphore 2**: Will be used to ensure that we don't present the image for display until after the command buffer is finished being processed
- **Fence**: Will be used to ensure we don't push more frames onto the queue than we support. Specifically, we don't want to re-use images when they're still in use by the GPU

Creating our semaphores and fences in Vulkan is super easy. We do need to use creation and destruction functions and pass some creation info but they hardly require any setup.

We'll make a single function to handle semaphores and fences, with the following signature

```rust
fn create_synchronization(
    device: &Device,
    amount: usize,
) -> Result<(Vec<Semaphore>, Vec<Semaphore>, Vec<Fence>)>
```

We require the logical device to be able to create N semaphores and fences, along with the amount to create, and then we simply return a tuple containing:
1. The semaphores to be used for the image being made available
2. The semaphores to be used for the command buffer having finished being processed
3. The fences to be used to allow the CPU to wait on a particular command buffer having been processed

Note that Vulkan doesn't guarantee that creation of these semaphores or fences is actually successful, so we need to return a Result to indicate that an error has occurred.

We'll first go ahead and make the builders for these create infos. The semaphore builder will be straightforward as there is nothing to configure.

For the fences, Vulkan will initially create them in an **unsignalled** state. However, in our case, we want them to start off **signalled** so that waiting on them will pass immediately the first time.

In order to do this we can pass a flag to the fence creation via the SIGNALED bit

```rust
let semaphore_builder = SemaphoreCreateInfo::builder();
let fence_builder = FenceCreateInfo::builder().flags(FenceCreateFlags::SIGNALED);
```

For the actual creation we can only make a single semaphore or fence at a time with Vulkan unfortunately, so we need to iterate from 0 to N, creating a semaphore/fence each time.

This results in an iterator over results, which can then be collected into a result of a Vec. Therefore this looks as follows

```rust
let image_available_semaphores = (0..amount)
    .map(|_| unsafe {
        device
            .create_semaphore(&semaphore_builder, None)
            .context("Failed to create an image available semaphore.")
    })
    .collect::<Result<Vec<_>>>()?;

let queue_submit_complete_semaphores = (0..amount)
    .map(|_| unsafe {
        device
            .create_semaphore(&semaphore_builder, None)
            .context("Failed to create a queue submit complete semaphore.")
    })
    .collect::<Result<Vec<_>>>()?;

let queue_submit_complete_fences = (0..amount)
    .map(|_| unsafe {
        device
            .create_fence(&fence_builder, None)
            .context("Failed to create a queue submit complete fence.")
    })
    .collect::<Result<Vec<_>>>()?;
```

Finally we can go ahead and return these in a tuple if all were created successfully

```rust
Ok((
    image_available_semaphores,
    queue_submit_complete_semaphores,
    queue_submit_complete_fences,
))
```

We'll have to remember to destroy these during clean-up too!

---
# Passing Data to the Draw Function #

Next we need to make sure that the main function passes along all the required data to the new draw function we'll make. In order to do this though, it first needs to be passed along to the run_event_loop function.

We update the signature to add all the additional parameters we need

```rust
fn run_event_loop(
    mut event_loop: EventLoop<()>,
    window: Window,
    device: &Device,
    swapchain: SwapchainKHR,
    image_available_semaphores: &[Semaphore],
    queue_submit_complete_semaphores: &[Semaphore],
    queue_submit_complete_fences: &[Fence],
    swapchain_ext: &Swapchain,
    graphics_queue: Queue,
    present_queue: Queue,
    command_buffers: &[CommandBuffer],
) -> i32
```

The main job of the run_event_loop will be to cycle through the semaphores/fences to ensure that not too many frames are in flight at once.

In order to do this we start off at frame number 0, and the maximum frame count/index we can have is limited by the number of entries in the semaphores (or fences) lists.

Therefore we can just take the length of the image_available_semaphores slice to figure out how many frames we can have in flight at a time.

```rust
let mut current_frame = 0;
let max_frames = image_available_semaphores.len();
```

We essentially want to call draw each frame, with the current frame number. Then after drawing we want to update the current frame number to the next one, wrapping around when we reach max_frames.

The call to draw, and the current_frame update looks as follows

```rust
draw(
    device,
    swapchain,
    image_available_semaphores[current_frame],
    queue_submit_complete_semaphores[current_frame],
    queue_submit_complete_fences[current_frame],
    swapchain_ext,
    graphics_queue,
    present_queue,
    command_buffers,
)
.unwrap();
current_frame = (current_frame + 1) % max_frames;
```

How do we ensure we do this every frame, or as fast as possible at least?. Winit actually provides a handy event type that we can hook into called **MainEventsCleared** so we put our logic in there.

---
# Drawing #

Finally we can implement our draw function body and get something shown on screen!

Each frame/draw function call, we follow the following sequence

![[Render Loop.png]]

#### On the Fence ####

The **very** first thing that we need to do is to ensure that the command buffer we will be submitting to the queue for processing isn't still being processed from a previous frame.

We don't want a backlog of work being submitted, since doing so would cause memory to just keep increasing so we can use the fence to let the CPU wait until the appropriate frame is finished being processed.

Visually, this can be represented with the following timeline diagram

![[How Fences Work.png]]

Code-wise, we can use a Vulkan function to cause the CPU to block while waiting for a fence to be signalled via the GPU. Vulkan allows us to wait on multiple fences at a time so the invocation takes a slice

```rust
device
    .wait_for_fences(&[queue_submit_complete_fence], true, u64::MAX)
    .context("Failed to wait for fence while drawing image.")?;
```

Parameters to the wait_for_fences function are
1. The slice containing the fences we're waiting for
2. Whether we are waiting for **all** the fences to be signalled. If this is false, this function only blocks the CPU until **one** has been signalled.
3. A timeout to block the CPU for. In our case we just want to block for however long it takes.

After having been signalled, we need to reset the fence manually for them to be re-usable next time

```rust
device
    .reset_fences(&[queue_submit_complete_fence])
    .context("Failed to reset fence while drawing image.")?;
```

#### Acquiring an Image ####

The first step of our sequence, now that we're cleared to continue by the fence, is to acquire the next available image from the swapchain.

We can do this with the acquire_next_image function of the swapchain extension, and it will provide us the index of the image that we should use immediately.

However, we can't actually *use* the image until it's stopped being used potentially from a previous frame. In order to sequence the command buffer execution until after the image is available, we'll use the image_available_semaphore.

Note that we are able to pass a fence through to this method so that we can block the CPU if needed until the image is acquired. However, blocking the CPU is heavy-handed in this case, so we just pass a null handle for the fence.

```rust
let (image_index, _) = swapchain_ext
    .acquire_next_image(
        swapchain,
        u64::MAX,
        image_available_semaphore,
        Fence::null(),
    )
    .context("Failed to acquire next image while drawing.")?;
```

Again, we set a timeout of u64::MAX since we want to block at least until Vulkan is able to tell us which image to use.

#### Submitting Command Buffer ####

Once we've acquired the image index we'll use, we need to submit the command buffer associated with that swapchain image to the graphics queue.

However this requires a lot of setup for synchronization purposes to make sure Vulkan respects the correct dependencies as it processes the commands we give it.

In particular, to submit to a queue we need:
1. A list of the semaphores that need to be triggered before this command buffer can start being processed.
2. A list of pipeline stages that we need to wait for before this command buffer can be processed.
3. A list of the command buffers that will be processed.
4. A list of semaphores that will be triggered/signalled when the command buffers have all finished being processing.

These lists will be as follows

```rust
let wait_semaphores = [image_available_semaphore];
let wait_dst_stages = [PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT];
let command_buffers = [command_buffers[image_index as usize]];
let signal_semaphores = [queue_submit_complete_semaphore];
```

The queue submission command can submit multiple things at once, so we will make an array but we only need a single submit info with the above

```rust
let submit_infos = [*SubmitInfo::builder()
    .wait_semaphores(&wait_semaphores)
    .wait_dst_stage_mask(&wait_dst_stages)
    .command_buffers(&command_buffers)
    .signal_semaphores(&signal_semaphores)];
```

Finally we can just go ahead and submit to the queue. We will submit to the **graphics** queue, and, equally importantly, we need to pass the fence through so that if the CPU spins around to this frame index again, they don't end up sending the same command buffer again while it's still being processed.

```rust
device
    .queue_submit(graphics_queue, &submit_infos, queue_submit_complete_fence)
    .context("Error while submitting command buffer to he queue during rendering.")?;
```

#### Presentation ####

The last step of the sequence after acquiring an image, and rendering to that image, is to present that image to be displayed.

To do this we need
1. A list of semaphores that the GPU needs signaled before proceeding to present
2. A list of swapchains to present to
3. A list of image indices on those swapchains to present

In our case we have only one of each again, so the code looks as follows

```rust
let wait_semaphores = [queue_submit_complete_semaphore];
let swapchains = [swapchain];
let image_indices = [image_index];
```

Then we submit to the queue!

```rust
swapchain_ext
    .queue_present(
        present_queue,
        &PresentInfoKHR::builder()
            .wait_semaphores(&wait_semaphores)
            .swapchains(&swapchains)
            .image_indices(&image_indices),
    )
    .context("Error while presenting image to the swapchain.")?;
```

Vulkan will then ensure it waits for the command buffer to be finished processing (thanks to the semaphore), and then dutifully present the image to the screen for us.

---
# Output #

Finally!, after 1000 lines of code, setting up every component of the pipeline required by Vulkan, we can go ahead and see the fruits of our labour!

Running our program we can see that avocado background we expect and a multi-coloured tria....wait, this doesn't look right

![Incorrect Rendering](Incorrectly%20Rendered%20Triangle.png)

We don't see our triangle....do we now have to go through 1000 lines of code to find the issue?

In this case, the reason was pretty simple to track down. We have enabled back face culling, and our viewport is rendered flipped over, thus the triangle is being culled out!

This is due to the coordinate systems in OpenGL and Vulkan being inverted.

OpenGL has the origin in the bottom left corner of the screen, and the y values going upwards toward the top of the screen, whereas Vulkan has the origin in the top left corner with the y axis running downwards.

Since we have our coordinates baked into our vertex shader at the moment which is written in GLSL, we're subject to OpenGL's coordinate system unfortunately.

The difference can be illustrated with the following diagram

![[Coordinate Systems In OpenGL And Vulkan.png]]

As detailed in the linked blog post, we can go ahead and flip our viewport over by specifying **negative** height to the viewport, causing it to grow **upwards**. However, due to the origin still being at the top left corner this would result in it being off-screen, thus we also need to offset the y position

```rust
let viewports = [Viewport {
    width: swapchain_extents.width as f32,
    height: -(swapchain_extents.height as f32),
    y: swapchain_extents.height as f32,
    max_depth: 1.0,
    ..Viewport::default()
}];
```

Doing this change results in the front face of our triangle being correctly displayed and thus we can see that it's now worked correctly!

![Correct Rendering](Correctly%20Rendered%20Triangle.png)