In this post we'll take a look at implementing the next (and final) level of abstraction for a neural network, the Network type itself.

Just as how we encapsulated multiple operations in a Layer type, the Network is nothing more than a wrapper around multiple layers. However this isn't *entirely* true, since the Network will also require a **loss function** in order to calculate the final single value measure of error for the predictions. We will then use the loss function also on the backward pass.

The way we train the network is the same as how we train the layers/operations and will consist of the following steps for a certain number of epochs:

1. Feed the data batch into each layer, taking the output of that layer and passing it to the next, until the output of the final layer is captured.
2. Feed the final output into the loss function, along with the expected targets to get the loss value.
3. Perform the backward pass on the loss function to get the output gradient to feed to the last layer, and continue passing the input gradient of a layer to the output gradient of the previous one.

Additionally, we'll need a way to get an iterator over all the parameters and parameter gradients of the network for training purposes, but as we'll see, this is nothing more than a wrapper over the layers as well.

---
# The Definition #

The type definition itself is very straightforward:

```rust
pub struct Network<T> {
    layers: Vec<Layer<T>>,
    loss: Loss<T>,
}
```

T here is, as in the layers/operations, the underlying element type of the Array type we're using to store the data.

For the Network type itself, it's just a Vec of layers, and a loss function as mentioned above.

---
# The "Constructor" #

For abstraction to allow for future private implementation changes, we will provide the user with a "new" method to create the Network as we do with the other types.

The type of T for creating a new Network doesn't need to be constrained, so the implementation is straightforward:

```rust
impl<T> Network<T> {
    pub fn new(layers: Vec<Layer<T>>, loss: Loss<T>) -> Self {
        Self { layers, loss }
    }
}
```

The rest of the methods we will implement require T to be clonable (due to the layers/operations needing to store off copies of their input for use on the backpropagation), these will therefore be in an impl block that looks like:

```rust
impl<T: Clone> Network<T> {
    ...
}
```

---
# Forward Function #

We want a public function that represents the forward pass of the network, but doesn't require a secondary testing array, since once the network is trained, we would like to use it to get predictions for new data such as from a testing data set.

This function does need to take a mutable reference to the Network since the forward pass causes copies of the input data to be stashed off in the layers/operations of the network. The signature for this function is pretty straightforward, just taking the input data and returning a batch of predictions:

```rust
pub fn forward(&mut self, batch: Array<T, Ix2>) -> Array<T, Ix2> {
    ...
}
```

As for the implementation, this is little more than running through each of the layers of the network, and calling its "forward" method to obtain output from that layer, then passing it through to the next and so on. In Rust with the iterator API we can easily model this as a fold expression:

```rust
self.layers
    .iter_mut()
    .fold(batch, |state, layer| layer.forward(&state))
```

---
# Forward Loss Function #

While we're training the network, we will want to run the forward pass, but also obtain the loss value at the end. This will never be called externally, and only is part of training the network, so it doesn't need to be public.

For the signature, we will take the input batch as before, but also because we're calculating the loss value will need to accept the array of targets as well.

The return value will be a tuple containing the predictions, and loss value.

Since the function is very simple, I'll just paste it in its entirety here:

```rust
fn forward_loss(&mut self, batch: Array<T, Ix2>, targets: Array<T, Ix2>) -> (Array<T, Ix2>, T) {
    let predictions = self.forward(batch);
    let loss = self.loss.forward(predictions.clone(), targets);
    (predictions, loss)
}
```

---
# Backward Pass #

Now that we have the forward pass covered, we need to look at the backward pass. Again, this is a private helper function that's only called as part of the training process and not independently. For the backward pass, we don't actually need to take any arguments.

We do however still need mutable access to the Network since the backward pass will calculate and update parameter gradients as it goes through.

As with the forward pass, this is modeled with a fold expression, calling the "backward" function on each layer with the result of the previous one. The code looks as follows:

```rust
fn backward(&mut self) {
    self.layers
        .iter_mut()
        .rev()
        .fold(self.loss.backward(), |gradient, layer| {
            layer.backward(&gradient)
        });
}
```

A couple of points to talk about:

1. We need to run through the layers in **reverse** order, because this is the backward pass. This is achieved by the **rev()** iterator adapter call.
2. In order to get the initial gradient, we call backward on the loss function. For the rest, we pass it through the layer.

---
# Training #

When we train the network, we are always performing a forward pass, followed by a backward pass. Therefore the public API for training the network doesn't expose the backward, or forward loss functions since the caller should only use the train function.

This function will take the input data, and target array. It will run the forward pass, followed by a backward pass. Finally it will return the loss that was determined from the forward pass because the training code may use this.

The function itself is just a wrapper around the forward_loss and backward function calls and looks as follows:

```rust
pub fn train(&mut self, batch: Array<T, Ix2>, targets: Array<T, Ix2>) -> T {
    let (_, loss) = self.forward_loss(batch, targets);
    self.backward();
    loss
}
```

---
# Parameter & Gradient Access #

This is the last part that's missing, which is the ability after training for an epoch, to obtain the parameters and parameter gradients from the network so that they can be optimized (e.g. via gradient descent).

Again, the function itself is very simple since all the complexity is now buried in the lower levels. Network is a wrapper, or composite over the layers and loss function, and so we're just composing the parameters and gradients from the layers.

What we want, is a parameters_and_gradients method that will return an iterator over each parameter and gradient in the first layer, then in the second, and so on.

We can achieve this in Rust by using the iterator adapter **flat_map**.

flat_map takes each element of the iterator it's adapting (in our case an iterator over the layers), and calls a closure on it. This closure returns an iterator, which Rust will chain together.

For our case, calling parameters_and_gradients on a *Layer* also returns an iterator, so it fulfils the contract for flat_map.

The full function then looks as follows:

```rust
pub fn parameters_and_gradients(
    &mut self,
) -> impl Iterator<Item = (&mut Array<T, Ix2>, &Array<T, Ix2>)> {
    self.layers
        .iter_mut()
        .flat_map(|layer| layer.parameters_and_gradients())
}
```

---
# Conclusion #

And that's all there is to the Network abstraction, just a bunch of composing and encapsulation!.

The final part of the implementation is to create types responsible for running the training of the Network, and for optimizing the parameters given the calculated gradients.

We'll look at implementing these in the next post.
