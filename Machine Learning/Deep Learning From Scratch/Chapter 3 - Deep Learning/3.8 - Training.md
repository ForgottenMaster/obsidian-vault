The last part to the puzzle, the last thing we need to do is to be able to encapsulate the algorithm for training a given network. In the book, this is represented as the "Trainer" type which binds together a network with an Optimiser instance. However there is only one implementation for this training process, and customisation is instead via the various trait objects in the Network setup, along with the selected Optimiser.

Therefore making it a type for no reason (a good reason would be to use it as a trait object for example) just results in more code. For now, training is just done via a single function which will take the Network and Optimiser to use.

---
# Algorithm #

As a reminder of the process that we will go through when we train, here is an overview of the sequence of steps that we will run each **epoch**

1. Clone the network if needed. We provide a tweakable value for the frequency to evaluate the network at (i.e. every X epochs). In the case that after evaluation the network is performing **worse** than before, then we terminate the training early and return to the previous network state. To restore the network state, we need to clone the network if it's one of these evaluation epochs.
2. Permute the data. When we feed the training data into the network, we feed it in a different order each epoch. Feeding data in the same batches each time can result in overfitting. permuting the samples each time helps the network to generalise.
3. Generate batches. We don't necessarily feed all the data into the network at once (we might do though, or might feed them one by one, or somewhere in between). We provide a parameter to the function to determine how large each batch of data is when we feed it through the network.
4. For each batch...
    1. Tell the network to perform a forward, and then a backward pass to calculate/update the parameter gradients.
    2. Tell the optmiser to apply its optimisation algorithm to update the parameters in the network for next epoch
5. If this is an evaluation epoch, check the loss value of the network after training...
    1. If it's worse then abort training and return the previous snapshot of the network
    2. If it's better, continue training and update the best loss value encountered for next evaluation

In order to achieve these we will need the following three functions, which we will cover in the following sections:

1. A function to permute the rows of the training data
2. A function to batch the rows of the training data up
3. A function to orchestrate the training algorithm

---
# Permuting the data #

As mentioned in the overview, to avoid overfitting the network to a specific setup or order of data, we want to shuffle the **rows** of the training data set around. Note that we want to always keep each row with its corresponding entry in the training target array.

This means that as we're shuffling, we need to apply the same ordering to both the training input data, and the training targets arrays.

In order to permute the data, we will essentially be shuffling the rows of the data in tandem with their target counterparts in the targets array. This means we must zip each row of the input data array with row in the targets array, to get a *single* list of **tuples** that we can then shuffle.

After shuffling, we need to re-split the data again into arrays to pass back.

NOTE: There's **definitely** a better way of building the output/permuted arrays than what I'm doing here, and there'll probably be an optimisation stage coming up before moving to the next chapter of the book which may also include refactoring the API to remove unnecessary traits, etc.

#### Signature ####

The signature of the permute_data method looks as follows:

```rust
fn permute_data<T: Clone + Default>(
    batch: &Array<T, Ix2>,
    targets: &Array<T, Ix2>,
    seed: Option<u64>,
) -> (Array<T, Ix2>, Array<T, Ix2>)
```

We require Cloning on the elements of the array, due to us using the **append** method to add rows to the arrays we're building up, this requires the elements to be cloned into the storage location. We require Default due to us wanting to initialise the output arrays with a set number of columns. Despite initialising with 0 rows, the Array::default method requires the type T to be default constructible.

For the other parameters, we take the batch of data to permute, and the targets array. We also take an optional random seed which is used to determine the random permutation order for the rows. We need to be able to specify this seed for unit testing, but in practice this will be given as None for "true" randomness.

The return values from this function are of course the permuted batch and targets arrays. These are returned by value as they are brand new arrays produced using the inputs as a basis.

#### Shape checking ####

The first step in the permutation is to cache the number of rows and columns in the batch and targets arrays (we expect the targets to only be a single column but it's indeed possible to produce more). We do require that the number of *rows* in the batch and targets arrays is the same though:

```rust
let (batch_row_count, batch_col_count) = (batch.nrows(), batch.ncols());
let (targets_row_count, targets_col_count) = (targets.nrows(), targets.ncols());
assert_eq!(batch_row_count, targets_row_count);
```

#### Zipping the arrays ####

In order to shuffle the batches and targets together we will need to zip them into a single vector. First step is to get an iterator that produces one row at a time from the Array. We can then zip those iterators together to get an iterator that produces a tuple with each step. The tuple has a row from each of the two arrays in it.

In order to produce an iterator over the rows of the array we can firstly get a flat slice of the data in the batch. This slice will have a row every NUM_COLS elements. We can use the **chunks** method on slices to get an iterator over chunks of size NUM_COLS which gives us the rows of the array.

This all looks as follows once coded up:

```rust
let batch_rows = batch.as_slice().unwrap().chunks(batch_col_count);
let targets_rows = targets.as_slice().unwrap().chunks(targets_col_count);
let mut zipped_rows = batch_rows.zip(targets_rows).collect::<Vec<_>>();
```

#### Creating the RNG ####

Next we need the random number generator. This construction is basically the same as we have for initialising the weights in the network and constructs either from the given seed if there is one, or constructs a random generator:

```rust
let mut random_generator = match seed {
    Some(seed) => StdRng::seed_from_u64(seed),
    None => StdRng::from_rng(thread_rng()).unwrap(),
};
```

#### Shuffling the data ####

Shuffling a vector with a random generator is an extension method provided to us by the rand crate. We can simply call it and pass a mutable reference to the generator. The reference needs to be mutable because the generator internally contains state it has to update upon generating a random number, in order to affect the next one produced.

This is a single line:

```rust
zipped_rows.shuffle(&mut random_generator);
```

#### Building the permuted arrays ####

In order to build the permuted arrays for returning, we will start with empty arrays, and then upon traversing the zipped vector, will add each row to the end of the appropriate array. This is analagous to building a Vec\<T> by iterating and pushing elements on one at a time. This is likely one of the things that isn't very efficient, but as a starting point it works.

There are a few ways that we can construct the initial Array instances, however we want to make sure that we are constructing **two dimensional** arrays, and that the number of columns we're specifying is correct. The choice I picked for initialising the arrays is using the default constructor. This takes a shape description. Initially we'll fix the number of columns, but will have 0 rows that will be extended as we append.

This default code looks as follows:

```rust
let mut batch = Array::default((0, batch_col_count));
let mut targets = Array::default((0, targets_col_count));
```

For the appending of the rows, we iterate over the entries in the zipped array. Remember that each entry in the zipped array is a tuple, where the first element is a row from the batch array, and the second is the corresponding row from the targets array.

The structure of the iteration then is as follows:

```rust
zipped_rows
    .into_iter()
    .for_each(|(batch_row, targets_row)| {
        // append code follows
    });
```

Only one thing remains, which is to actually append batch_row to the batch array we're building, and targets_row to the targets array we're building. As mentioned before, we use the **append** method on the array. This method takes two parameters:

1. An axis along which we're appending the new data - in our case this will be the 0th axis (rows) as we're adding each row as a row in the Array.
2. An array or array view to append - in this case, we just shape the row data into an ArrayView with 1 row, and the requisite number of columns.

The code for this when updating the batch looks like follows:

```rust
batch
    .append(
        Axis(0),
        ArrayView::from_shape((1, batch_col_count), batch_row).unwrap(),
    )
    .unwrap();
```

And the targets follows the same format:

```rust
targets
    .append(
        Axis(0),
        ArrayView::from_shape((1, targets_col_count), targets_row).unwrap(),
    )
    .unwrap();
```

---
# Generating the batches #

In comparison to the function to permute the arrays, generating the batches to feed into the network for training is shorter. Essentially what we would like is to get an iterator over two arrays (the batch and targets arrays).

Each element in this iterator will be a pair of new arrays. One array will be a batch of rows from the "batches" input array, and the next will be a batch of rows from the "targets" input array.

Since we are yielding new arrays from the iterator, we need elements to be cloneable, which is why we require the element type in the arrays to be cloneable. Since we don't require ownership of the input arrays and are simply producing new arrays from them, we take references to them. However, since we're yielding an iterator over those arrays, we must make sure the lifetime of the produced iterator is tied to them, so we can't drop them before being finished with the iterator.

This results in the following signature:

```rust
fn generate_batches<'a, T: Clone>(
    batch: &'a Array<T, Ix2>,
    targets: &'a Array<T, Ix2>,
    size: usize,
) -> impl Iterator<Item = (Array<T, Ix2>, Array<T, Ix2>)> + 'a
```

Firstly, we need to make sure that both input arrays have the same number of rows. Each yielded tuple is a row from each, so they must match:

```rust
assert_eq!(batch.nrows(), targets.nrows());
```

In order to produce the desired iterator we need to do the following:

1. Get an iterator over chunks of **size** rows from the batch array
2. Get an iterator over chunks of **size** rows from the targets array
3. Zip the two together to get an iterator over chunks from both arrays
4. Map this tuple of array views into a tuple of owned arrays

For steps 1 and 2 we can use the built in method on arrays **axis_chunks_iter** which takes an axis along which to iterate (again we will iterate over the 0th axis - the rows), and the size we would like each cunk to be.

For step 3 we use zip to zip the iterators together.

For step 4 we can use the map adapter, and use the **to_owned** method to turn the ArrayView chunks into owned Array instances.

The full code for this will look as follows:

```rust
batch
    .axis_chunks_iter(Axis(0), size)
    .zip(targets.axis_chunks_iter(Axis(0), size))
    .map(|(view1, view2)| (view1.to_owned(), view2.to_owned()))
```

---
# The training function #

Finally we can implement the main attraction, the function which will take the network to train, an optimisation strategy, and the training+testing data, along with other parameters and actually run the training process on the network.

The signature for it isn't exactly pretty:

```rust
pub fn train<T: Clone + Default + PartialOrd>(
    network: &mut Network<T>,
    optimiser: &mut impl Optimiser<T>,
    batch_train: Array<T, Ix2>,
    targets_train: Array<T, Ix2>,
    batch_test: Array<T, Ix2>,
    targets_test: Array<T, Ix2>,
    epochs: u32,
    eval_every: u32,
    batch_size: usize,
    seed: Option<u64>,
)
```

Firstly an explanation of the traits in use:

1. Clone: We need to clone the Network\<T> in order to create a snapshot/undo point for early termination. We can only do this if T itself is Clone
2. Default: This is required because as explained before, permute_data requires T to be Default
3. PartialOrd: We need to evaluate the calculated loss from the network against the previous best loss for early termination. In order to do this, we need the loss value (of type T) to support comparison

Next, we'll explain the parameters of the train function (although they'll be fairly self explanatory):

1. network: The neural network to train, taken my **mutable** reference as we need to update the parameters within
2. optimiser: The optimisation strategy to use, also taken by mutable reference, in case the optimiser stores state between epochs
3. batch_train: The input data from the training batch
4. targets_train: The output data/targets for the training batch
5. batch_test: The input data from the *testing* batch
6. targets_test: The output data/targets for the *testing* batch
7. epochs: The **maximum** number of iterations of training that we will go through
8. eval_every: The frequency at which we evaluate the loss, and revert to the previous state/abort if it regresses
9. batch_size: The size of each batch we feed through the network during a given epoch
10. seed: An *optional* seed for the RNG when training. During testing this will be provided, during normal use it should be None

Note that epochs is the maximum number of epochs we go through, since we're implementing early stopping if the loss regresses and starts to diverge from the desired loss.

We make a variable to track the "best" loss value during evaluation, which needs to be mutable as we upate it as we train. The actual iteration over the epochs is as expected:

```rust
let mut best_loss = None;
for e in 0..epochs {
    // training code here
}
```

Note that we do need to use a traditional for loop, rather than a for_each call on the iterator because we can't early abort the for_each style where we can break out of a traditional loop.

The first step in the epoch is to store off a snapshot of the Network **if necessary**. We don't need to clone the network every epoch, just at the frequency we are evaluating. We therefore use an Option<Network\<T>> to store the snapshot:

```rust
let last_model = if (e + 1) % eval_every == 0 {
    Some((*network).clone())
} else {
    None
};
```

Secondly comes the actual training for the epoch. The sequence of steps for this will be:

1. Permute the training data
2. Generate batches from the training data
3. For each batch, train the network, and step the optimiser

In code this looks like the following:

```rust
let (batch_train, targets_train) = permute_data(&batch_train, &targets_train, seed.clone());
generate_batches(&batch_train, &targets_train, batch_size).for_each(|(batch, targets)| {
    network.train(batch, targets);
    optimiser.step(network);
});
```

Finally, after training the network for one epoch, if we need to evaluate the loss, we do that. We can use the **forward_loss** method on the testing data in order to get the predictions (which we won't use), and the loss value (which we will). If the best loss so far is None, or if this one is better, then we update the best loss value and continue. In the case that the loss is now *worse* than we had, we revert to the snapshot and break the training process.

Code for all of this is shown below:

```rust
if let Some(last_model) = last_model {
    let (_, test_loss) = network.forward_loss(batch_test.clone(), targets_test.clone());
    if best_loss.is_none() || test_loss < *best_loss.as_ref().unwrap() {
        best_loss = Some(test_loss);
    } else {
        *network = last_model;
        break;
    }
}
```