Now that the layers of abstraction are done, we need to work on actually running the training of the network. We will be encapsulating the optimisation process to allow for the API user to select the strategy they would like to use to apply the gradients to parameters when training the network. This will be a fairly short post as the actual optimisation process is pretty simple.

---
# The Trait #

An Optimiser has a single job in the network training process. To apply the calculated partial derivatives for the parameter operations in the network to the parameters themselves. The basic form as we'll see shortly is just applying some proportion of the gradients to the parameters.

However, it's entirely possible the API user may wish to update them in a different way, such as updating using a historical average to smooth out the modifications over time.

At the end of the day though, the Optimiser trait only needs a single method, which is called to update the provided Network. The trait definition is as follows:

```rust
pub trait Optimiser<T> {
    fn step(&mut self, net: &mut Network<T>);
}
```

Again it needs a generic type, T, which is the type of the underlying elements in the arrays within the network.

The step function operates on a **mutable** reference to the Optimiser object itself, because it may want to for example store a history of gradients, or other information. Updating that information stored in the members of the implementor requires mutable access.

It takes the Network in by mutable reference also. We don't want the implementor to *own* the Network, but merely borrow it for the duration of the step function. We need mutable access because we need access to and to update the parameters within the network.

---
# Stochastic Gradient Descent #

This is the official terminology for the optimisation algorithm used previously. This simply runs through the parameters and gradients of the network and applies some proportion of the gradient to the parameter. This multiplier is called the **learning rate**.

As far as the structure of the SGD struct itself, we need to store the learning rate that is to be applied. This is an instance of the generic type T since we don't know what concrete type is being used to store data within the network.

This definition then looks fairly trivial:

```rust
pub struct SGD<T> {
    learning_rate: T,
}
```

Secondly, we will need a way to construct a new instance of the struct. We will do this by adding a **new_boxed** method, since we need to store the optimiser as a trait object, thus it will need to be placed behind a box.

The implementation of new_boxed then shouldn't be much of a surprise:

```rust
impl<T> SGD<T> {
    pub fn new_boxed(learning_rate: T) -> Box<Self> {
        Box::new(Self { learning_rate })
    }
}
```

For the implementation of the Optimiser trait on SGD, it will look as follows:

```rust
impl<T: LinalgScalar + ScalarOperand> Optimiser<T> for SGD<T> {
    ...
}
```

These bounds are required due to the implementation of the function requiring arithmetic operations on the elements of the parameters and gradients arrays.

As for the implementation of the step function, it's simply running over each parameter & gradient pair, and subtracting a small portion of the gradient (dictated by learning_rate) from the parameter:

```rust
net.parameters_and_gradients()
    .for_each(|(param, gradient)| {
        *param = &*param - (gradient * self.learning_rate);
    });
```

This runs the following sequence of operations:

1. Calls parameters_and_gradients on the network which, as you may recall, returns an **impl Iterator<Item=(&mut Array\<T>, &Array\<T>)>** object. That is we don't know what the concrete type is, but we do know that it implements the Iterator trait.
2. We run code for each parameter and gradient pair. We use the for_each method here rather than a regular for loop in order to communicate the semantics that we are indeed updating every entry.
3. We can multiply an Array\<T> by a single value T thanks to the ScalarOperand bound.
4. We need to do a reborrow in this code since subtraction isn't implemented for a left hand side of a *mutable* reference to an Array. We also can't just dereference param since that would result in calling the implementation of the operator that takes an owned value on the left hand side. Therefore we need to reborrow the mutable reference as an immutable one and the compiler will find the function correctly.