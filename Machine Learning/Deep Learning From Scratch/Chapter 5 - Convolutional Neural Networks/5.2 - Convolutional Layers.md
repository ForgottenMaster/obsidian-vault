The previous post explained the basic multichannel convolution operation but we now take a look at how we can integrate it into a neural network.

---
# Architecture #

In a regular dense layer we can think of a first hidden layer outputting h1 neurons, or learned features.

If we have another hidden layer taking these h1 neurons as input and producing h2 neurons then this layer needs h1 x h2 weights in order to represent that each of the output neurons is some linear combination of all the input neurons.

With convolutional layers, the process is the same except that instead of h1 x h2 *neurons* we have the same number of *convolutional filters* to represent that each output channel is some combination of the input channels.

We can define the dimensions of the ndarrays that are making up the input, output, and parameters of the multichannel operation as follows.

1. The input has shape **(batch size, input channels, image height, image width)**
2. The output has shape **(batch size, output channels, image height, image width)**
3. The convolutional filters have shape **(input channels, output channels, filter height, filter width)**

---
# Comparing Dense And Convolutional Layers #

Convolutional layers are analagous to dense/fully connected layers but with extra dimensions at work.

The comparison can be visualised as follows:

![Comparison](Comparison.png)

The interpretation of a neuron differs subtly between the two as well:

1. In a dense layer, a neuron represents whether a particular combination of the features learned by the prior layer is present
2. In a convolutional layer, a neuron represents whether a particular combination of visual patterns learned by the prior layer is present at a given location in the input image

---
# Pooling Layers #

Since the size and number of the matrices at work in a CNN are an order larger than those in a standard feed-forward neural network, the computations can get expensive.

In order to help with performance, pooling layers provide a way to *downsample* each of the feature maps created from a convolution operation.

For the commonly used pooling size of 2, this means taking each 2x2 patch in the data to a single value, thus cutting the dimensions in half (and the data overall by 4).

The two types of pooling commonly used are:

1. Max-Pooling: The maximum value in the section is taken
2. Average-Pooling: The average of the values in the section is taken

These can be visualised in the following example:

![Pooling](Convolutional%20Pooling.png)

The downside of pooling layers is that a lot of information is lost and so the training likely won't be as accurate.

Modern CNNs don't use pooling much, if at all.