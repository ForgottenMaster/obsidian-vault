Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.

---
# High level review #

We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records. These predictions are then compared with the known targets during the training process to see how close they are (using the loss function).

Therefore this high level intuition can be represented by the following diagram

![High level neural net diagram](Overview%20Of%20Training.png)

---
# A more accurate representation #

The above diagram is good for seeing at a high level that neural networks are treated as black boxes to produce predictions and can be trained to produce better predictions, however what is really happening under the hood is that we're tweaking the weights in such a way as to represent the complex mathematical function between the set of weights and the output loss that those weights produce (given a static set of inputs and outputs).

This graph between the weights and the loss can be shown as follows

![Lower level diagram](Mathematical%20Representation%20Of%20Function.png)

---
# Training #

With the above graph representation we can see that as the set of weights vary along the horizontal axis, the loss, or error, of the network can be greater or lower (actually the set of weights isn't a single value to be plotted on an axis, but it helps intuition to think of it as a single dimension on which a single point is a set of values for all weights in the network).

The training process is then represented as starting from one point, or set of weights and using the learning rate, determining a new set of weights and continuing until we settle on the set of weights producing the lowest loss.

We can view this process as the following diagram

![Training illustration](Diagram%20Of%20Training.png)

In the above diagram, the blue arrows show the process with a small learning rate, that is we move only slightly to the next set of weights. The red arrows represent a large learning rate which causes the set of weights and resulting loss to "bounce around" more than it might want to.

---
# The problem #

As we can see from the diagram, we would like to find the set of weights that gives the lowest **global** loss across all sets of weights, however with a very small learning rate we risk the chance of falling into a **local** minima and accepting a sub-optimal solution.

If the steps we take are too large (the red arrows), then we might be near the global minimum but we might end up "skipping over" it repeatedly and again accepting a sub-optimal solution.

The tricks and tweaks described and implemented in the coming posts serve as to allow us to efficiently locate this global minimum without falling into a false, local minimum.